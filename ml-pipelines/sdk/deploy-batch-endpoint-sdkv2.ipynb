{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient, command, Input, Output, load_component\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Data, Environment\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "from azure.ai.ml.dsl import pipeline"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1727326603419
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credential = DefaultAzureCredential()\n",
        "ml_client = None\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    # Enter details of your AML workspace\n",
        "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "    resource_group = \"<RESOURCE_GROUP>\"\n",
        "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
        "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1727326603533
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Endpoint\n",
        "\n",
        "**Batch endpoints** are endpoints that are used to do batch inferencing on large volumes of data over a period of time. \n",
        "\n",
        "**Batch endpoints** receive pointers to data and run jobs asynchronously to process the data in parallel on compute clusters. Batch endpoints store outputs to a data store for further analysis.\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/endpoint_batch_concept.png\" width = \"700px\" alt=\"Concept batch endpoint\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create Batch Compute Cluster (Optional)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "try:\n",
        "    ml_client.compute.get(name=\"cpu-cluster\")\n",
        "    print(\"Compute already exists\")\n",
        "\n",
        "except:\n",
        "    print(\"Compute not found; Proceding to create\")\n",
        "\n",
        "    my_cluster = AmlCompute(\n",
        "        name=\"cpu-cluster\",\n",
        "        type=\"amlcompute\", \n",
        "        size=\"STANDARD_DS1_V2\", \n",
        "        min_instances=0, \n",
        "        max_instances=3,\n",
        "    )\n",
        "    ml_client.compute.begin_create_or_update(my_cluster)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Compute already exists\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1727326719390
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Batch Endpoint\n",
        "\n",
        "We can create the **batch endpoint** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_batch_endpoint.png\" width = \"700px\" alt=\"Create batch endpoint cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create batch endpoint\n",
        "from azure.ai.ml.entities import BatchEndpoint\n",
        "import random\n",
        "\n",
        "rand = random.randint(0, 10000)\n",
        "\n",
        "endpoint_name = f\"taxi-batch-endpoint-{rand}\"\n",
        "batch_endpoint = BatchEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"Taxi batch endpoint\",\n",
        "    tags={\"model\": \"taxi-model@latest\"},\n",
        ")\n",
        "\n",
        "poller = ml_client.batch_endpoints.begin_create_or_update(batch_endpoint)\n",
        "poller.wait()\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1727326762366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.exceptions import DeploymentException\n",
        "\n",
        "status = poller.status()\n",
        "if status != \"Succeeded\":\n",
        "    raise DeploymentException(status)\n",
        "else:\n",
        "    print(\"Endpoint creation succeeded\")\n",
        "    endpoint = poller.result()\n",
        "    print(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint creation succeeded\n{'additional_properties': {}, 'id': '/subscriptions/14585b9f-5c83-4a76-8055-42149123f99f/resourceGroups/mldemorg/providers/Microsoft.MachineLearningServices/workspaces/mldemo/batchEndpoints/taxi-batch-endpoint-6853', 'name': 'taxi-batch-endpoint-6853', 'type': 'Microsoft.MachineLearningServices/workspaces/batchEndpoints', 'system_data': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f085c30ceb0>, 'tags': {'model': 'taxi-model@latest'}, 'location': 'eastus2', 'identity': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity object at 0x7f085c30e620>, 'kind': None, 'properties': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.BatchEndpointDetails object at 0x7f085c30e200>, 'sku': None}\n"
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create Batch Deployment\n",
        "\n",
        "We can create the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/create_batch_deployment.png\" width = \"700px\" alt=\"Create batch deployment cli vs sdk\">\n",
        "</center>\n",
        "\n",
        "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create batch deployment\n",
        "from azure.ai.ml.entities import BatchDeployment, Model, Environment\n",
        "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
        "\n",
        "model = \"taxi-model@latest\"\n",
        "\n",
        "batch_deployment = BatchDeployment(\n",
        "    name=\"taxi-batch-dp\",\n",
        "    description=\"this is a sample batch deployment\",\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=model,\n",
        "    compute=\"cpu-cluster\",\n",
        "    instance_count=2,\n",
        "    max_concurrency_per_instance=2,\n",
        "    mini_batch_size=10,\n",
        "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "    output_file_name=\"predictions.csv\",\n",
        ")\n",
        "\n",
        "poller = ml_client.begin_create_or_update(batch_deployment)\n",
        "poller.wait()\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1727328233244
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set deployment as the default deployment in the endpoint:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_endpoint = ml_client.batch_endpoints.get(endpoint_name)\n",
        "batch_endpoint.defaults.deployment_name = batch_deployment.name\n",
        "poller = ml_client.batch_endpoints.begin_create_or_update(batch_endpoint)\n",
        "poller.wait()"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1727328268511
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Invoke and Test Endpoint\n",
        "\n",
        "We can invoke the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
        "\n",
        "<center>\n",
        "<img src=\"../../imgs/invoke_batch_deployment.png\" width = \"700px\" alt=\"Invoke batch deployment cli vs sdk\">\n",
        "</center>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke and test endpoint\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "\n",
        "input = Input(path=\"../../data/taxi-batch.csv\", \n",
        "              type=AssetTypes.URI_FILE, \n",
        "              mode=InputOutputModes.DOWNLOAD)\n",
        "\n",
        "\n",
        "# invoke the endpoint for batch scoring job\n",
        "ml_client.batch_endpoints.invoke(\n",
        "    endpoint_name=endpoint_name,\n",
        "    input=input,\n",
        "    deployment_name=\"taxi-batch-dp\"\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading taxi-batch.csv\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading taxi-batch.csv\u001b[32m (< 1 MB): 100%|██████████| 133k/133k [00:00<00:00, 8.36MB/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1668689480461
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}